import streamlit as st
import pandas as pd
from io import BytesIO
import io
from datetime import datetime
import os
import time
import plotly.express as px
import plotly.graph_objects as go
import math
import boto3
import json
import logging
from functools import lru_cache
from botocore.exceptions import NoCredentialsError, PartialCredentialsError, ClientError
import zipfile

# Try to import reportlab for PDF generation
try:
    from reportlab.lib.pagesizes import letter, A4
    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, PageBreak
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.lib.units import inch
    from reportlab.lib import colors
    from reportlab.lib.enums import TA_CENTER, TA_LEFT
    REPORTLAB_AVAILABLE = True
except ImportError:
    REPORTLAB_AVAILABLE = False

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Configure page
st.set_page_config(
    page_title="Enterprise AWS EC2 Workload Sizing Platform",
    layout="wide",
    page_icon="üè¢",
    initial_sidebar_state="expanded"
)

# Enhanced custom CSS - Fixed Google Fonts URL
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');

    html, body, [class*="css"] {
        font-family: 'Inter', sans-serif;
    }
    h1, h2, h3, h4, h5, h6 {
        font-family: 'Inter', sans-serif;
        font-weight: 600;
        color: #1a202c;
    }
    .stApp {
        background-color: #f7fafc;
    }
    .main-header {
        text-align: center;
        padding: 2rem;
        background: linear-gradient(to right, #667eea, #764ba2);
        color: white;
        border-radius: 0.5rem;
        margin-bottom: 2rem;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    .main-header h1 {
        color: white;
        font-weight: 700;
        margin-bottom: 0.5rem;
    }
    .main-header p {
        color: #e2e8f0;
        font-size: 1.1rem;
    }
    .stButton>button {
        background-color: #4c51bf;
        color: white;
        font-weight: 600;
        border-radius: 0.5rem;
        border: none;
        padding: 0.6rem 1.2rem;
        transition: all 0.2s ease-in-out;
    }
    .stButton>button:hover {
        background-color: #5a67d8;
        transform: translateY(-2px);
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
    }
    .stButton>button:active {
        transform: translateY(0);
    }
    .stTabs [data-baseweb="tab-list"] button {
        background-color: #e2e8f0;
        color: #4a5568;
        border-radius: 0.5rem 0.5rem 0 0;
        margin-right: 0.25rem;
        padding: 0.75rem 1.25rem;
        font-weight: 500;
        transition: all 0.2s ease-in-out;
    }
    .stTabs [data-baseweb="tab-list"] button:hover {
        background-color: #cbd5e0;
    }
    .stTabs [data-baseweb="tab-list"] button[aria-selected="true"] {
        background-color: #ffffff;
        color: #4c51bf;
        border-bottom: 3px solid #4c51bf;
    }
    .stTabs [data-baseweb="tab-panel"] {
        background-color: #ffffff;
        padding: 1.5rem;
        border-radius: 0 0.5rem 0.5rem 0.5rem;
        box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }
    .stMetric {
        background-color: #ffffff;
        border: 1px solid #e2e8f0;
        border-radius: 0.5rem;
        padding: 1rem;
        margin-bottom: 1rem;
        box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }
    .stProgress > div > div > div > div {
        background-color: #4c51bf;
    }
    .status-badge {
        display: inline-flex;
        align-items: center;
        padding: 0.25rem 0.75rem;
        border-radius: 9999px;
        font-size: 0.875rem;
        font-weight: 600;
        margin-right: 0.5rem;
    }
    .status-success {
        background-color: #d1fae5;
        color: #065f46;
    }
    .status-error {
        background-color: #fee2e2;
        color: #991b1b;
    }
    .stAlert {
        border-radius: 0.5rem;
    }
    code {
        background-color: #edf2f7;
        padding: 0.2em 0.4em;
        border-radius: 0.2rem;
        font-family: 'Fira Code', monospace;
    }
</style>
""", unsafe_allow_html=True)

# Constants for regions and OS for dropdowns
AWS_REGIONS = {
    "US East (N. Virginia)": "us-east-1",
    "US East (Ohio)": "us-east-2",
    "US West (N. California)": "us-west-1",
    "US West (Oregon)": "us-west-2",
    "Europe (Ireland)": "eu-west-1",
    "Europe (Frankfurt)": "eu-central-1",
    "Asia Pacific (Singapore)": "ap-southeast-1",
    "Asia Pacific (Sydney)": "ap-southeast-2",
    "Asia Pacific (Tokyo)": "ap-northeast-1",
    "Asia Pacific (Seoul)": "ap-northeast-2",
    "Asia Pacific (Mumbai)": "ap-south-1",
    "Asia Pacific (Hong Kong)": "ap-east-1"
}

OPERATING_SYSTEMS = {
    "Linux (RHEL)": "RHEL",
    "Linux (Ubuntu)": "Ubuntu Pro",
    "Linux (Amazon Linux 2)": "Linux",
    "Windows Server": "Windows"
}

WORKLOAD_TYPES = [
    "Web Application", "Application Server", "Database Server",
    "File Server", "Compute Intensive", "Other"
]

# Instance types to exclude from recommendations
EXCLUDE_INSTANCE_TYPES = [
    "t1.micro", "m1.small", "m1.medium", "m1.large", "m1.xlarge",
    "c1.medium", "c1.xlarge", "m2.xlarge", "m2.2xlarge", "m2.4xlarge",
    "m3.medium", "m3.large", "m3.xlarge", "m3.2xlarge", "c3.large",
    "c3.xlarge", "c3.2xlarge", "c3.4xlarge", "c3.8xlarge", "r3.large",
    "r3.xlarge", "r3.2xlarge", "r3.4xlarge", "r3.8xlarge",
    "i2.xlarge", "i2.2xlarge", "i2.4xlarge", "i2.8xlarge",
    "d2.xlarge", "d2.2xlarge", "d2.4xlarge", "d2.8xlarge",
    "t2.nano", "t2.micro", "t2.small", "t2.medium", "t2.large", "t2.xlarge", "t2.2xlarge",
    "c4.large", "c4.xlarge", "c4.2xlarge", "c4.4xlarge", "c4.8xlarge",
    "m4.large", "m4.xlarge", "m4.2xlarge", "m4.4xlarge", "m4.10xlarge", "m4.16xlarge",
    "r4.large", "r4.xlarge", "r4.2xlarge", "r4.4xlarge", "r4.8xlarge", "r4.16xlarge",
    "x1.16xlarge", "x1.32xlarge", "x1e.xlarge", "x1e.2xlarge", "x1e.4xlarge", "x1e.8xlarge", "x1e.16xlarge", "x1e.32xlarge",
    "p2.xlarge", "p2.8xlarge", "p2.16xlarge", "p3.2xlarge", "p3.8xlarge", "p3.16xlarge",
    "g3.4xlarge", "g3.8xlarge", "g3.16xlarge"
]

# Simplified RI/SP discount rates
RI_SP_DISCOUNTS = {
    "On-Demand": 0.0,
    "1-Year No Upfront RI/SP": 0.30,
    "3-Year No Upfront RI/SP": 0.50
}

# Region name mapping for AWS Pricing API
PRICING_REGION_NAMES = {
    "us-east-1": "US East (N. Virginia)",
    "us-east-2": "US East (Ohio)",
    "us-west-1": "US West (N. California)",
    "us-west-2": "US West (Oregon)",
    "eu-west-1": "Europe (Ireland)",
    "eu-central-1": "Europe (Frankfurt)",
    "ap-southeast-1": "Asia Pacific (Singapore)",
    "ap-southeast-2": "Asia Pacific (Sydney)",
    "ap-northeast-1": "Asia Pacific (Tokyo)",
    "ap-northeast-2": "Asia Pacific (Seoul)",
    "ap-south-1": "Asia Pacific (Mumbai)",
    "ap-east-1": "Asia Pacific (Hong Kong)"
}

# --- AWS Price Fetching and Calculation Logic ---
class AWSCalculator:
    def __init__(self):
        self.pricing_client = None
        self.ec2_client = None
        self.all_ec2_prices = {}
        self.all_ebs_prices = {}
        self.inputs = {}
        self._instance_details_cache = {}

    def _get_pricing_client(self):
        """Initializes the AWS Pricing client."""
        try:
            return boto3.client('pricing', region_name='us-east-1')
        except (NoCredentialsError, PartialCredentialsError) as e:
            logger.error(f"AWS credentials error: {e}")
            return None
        except Exception as e:
            logger.error(f"Error initializing AWS Pricing client: {e}")
            return None

    def _get_ec2_client(self, region):
        """Initializes the AWS EC2 client for a specific region."""
        try:
            return boto3.client('ec2', region_name=region)
        except (NoCredentialsError, PartialCredentialsError) as e:
            logger.error(f"AWS credentials error for region {region}: {e}")
            return None
        except Exception as e:
            logger.error(f"Error initializing AWS EC2 client for region {region}: {e}")
            return None

    def validate_aws_credentials(self):
        """Validates AWS credentials by trying to list EC2 regions."""
        try:
            ec2 = boto3.client('ec2', region_name='us-east-1')
            ec2.describe_regions()
            return True, "Successfully connected to AWS."
        except (NoCredentialsError, PartialCredentialsError):
            return False, "AWS credentials not configured or incomplete."
        except ClientError as e:
            if e.response['Error']['Code'] == 'AuthFailure':
                return False, "Authentication failed. Check your AWS credentials and permissions."
            return False, f"AWS Client Error: {e}"
        except Exception as e:
            return False, f"An unexpected error occurred: {e}"

    def fetch_current_prices(self):
        """Fetches EC2 and EBS prices for all regions."""
        self.pricing_client = self._get_pricing_client()
        if not self.pricing_client:
            st.error("Failed to initialize AWS Pricing client. Please check your credentials.")
            return

        self.all_ec2_prices = {}
        self.all_ebs_prices = {}

        regions_to_fetch = list(AWS_REGIONS.values())
        progress_bar_text = st.empty()
        progress_bar = st.progress(0)
        total_regions = len(regions_to_fetch)

        for i, region in enumerate(regions_to_fetch):
            progress_bar_text.text(f"Fetching prices for region: {region} ({i+1}/{total_regions})...")
            progress_bar.progress((i + 1) / total_regions)
            
            try:
                # Fetch EC2 On-Demand Prices
                self.all_ec2_prices[region] = self._fetch_ec2_prices_for_region(region)
                # Fetch EBS Prices
                self.all_ebs_prices[region] = self._fetch_ebs_prices_for_region(region)
                
            except Exception as e:
                logger.error(f"Error fetching prices for {region}: {e}")
                st.warning(f"Could not fetch all prices for {region}. Error: {e}")
                self.all_ec2_prices[region] = {}
                self.all_ebs_prices[region] = {}

        progress_bar_text.empty()
        progress_bar.empty()
        logger.info("Finished fetching prices.")

    def _fetch_ec2_prices_for_region(self, region):
        """Fetch EC2 prices for a specific region."""
        region_ec2_prices = {}
        location_name = PRICING_REGION_NAMES.get(region, region)
        
        try:
            paginator = self.pricing_client.get_paginator('get_products')
            response_iterator = paginator.paginate(
                ServiceCode='AmazonEC2',
                Filters=[
                    {'Type': 'TERM_MATCH', 'Field': 'location', 'Value': location_name},
                    {'Type': 'TERM_MATCH', 'Field': 'productFamily', 'Value': 'Compute Instance'},
                    {'Type': 'TERM_MATCH', 'Field': 'preInstalledSw', 'Value': 'NA'},
                    {'Type': 'TERM_MATCH', 'Field': 'tenancy', 'Value': 'Shared'},
                    {'Type': 'TERM_MATCH', 'Field': 'capacitystatus', 'Value': 'Used'}
                ]
            )
            
            for page in response_iterator:
                for price_item in page['PriceList']:
                    try:
                        product = json.loads(price_item)
                        attributes = product['product']['attributes']
                        
                        instance_type = attributes.get('instanceType')
                        operating_system = attributes.get('operatingSystem')
                        
                        if not instance_type or not operating_system:
                            continue
                            
                        # Normalize OS names
                        if operating_system.lower() == 'linux':
                            operating_system = 'Linux'
                        elif operating_system.lower() == 'rhel':
                            operating_system = 'RHEL'
                        elif 'ubuntu' in operating_system.lower():
                            operating_system = 'Ubuntu Pro'
                        elif operating_system.lower() == 'windows':
                            operating_system = 'Windows'
                        
                        # Extract pricing information
                        terms = product.get('terms', {})
                        on_demand = terms.get('OnDemand', {})
                        
                        for term_key, term_value in on_demand.items():
                            price_dimensions = term_value.get('priceDimensions', {})
                            for price_key, price_value in price_dimensions.items():
                                price_per_unit = price_value.get('pricePerUnit', {}).get('USD', '0')
                                try:
                                    price_float = float(price_per_unit)
                                    if price_float > 0:
                                        if instance_type not in region_ec2_prices:
                                            region_ec2_prices[instance_type] = {}
                                        region_ec2_prices[instance_type][operating_system] = price_float
                                        break
                                except (ValueError, TypeError):
                                    continue
                            break
                    except (json.JSONDecodeError, KeyError) as e:
                        continue
                        
        except Exception as e:
            logger.error(f"Error fetching EC2 prices for region {region}: {e}")
            
        return region_ec2_prices

    def _fetch_ebs_prices_for_region(self, region):
        """Fetch EBS prices for a specific region."""
        region_ebs_prices = {}
        location_name = PRICING_REGION_NAMES.get(region, region)
        
        try:
            paginator = self.pricing_client.get_paginator('get_products')
            response_iterator = paginator.paginate(
                ServiceCode='AmazonEC2',
                Filters=[
                    {'Type': 'TERM_MATCH', 'Field': 'location', 'Value': location_name},
                    {'Type': 'TERM_MATCH', 'Field': 'productFamily', 'Value': 'Storage'},
                    {'Type': 'TERM_MATCH', 'Field': 'volumeType', 'Value': 'General Purpose'}
                ]
            )
            
            for page in response_iterator:
                for price_item in page['PriceList']:
                    try:
                        product = json.loads(price_item)
                        attributes = product['product']['attributes']
                        
                        volume_type = attributes.get('volumeType')
                        if volume_type != 'General Purpose':
                            continue
                            
                        terms = product.get('terms', {})
                        on_demand = terms.get('OnDemand', {})
                        
                        for term_key, term_value in on_demand.items():
                            price_dimensions = term_value.get('priceDimensions', {})
                            for price_key, price_value in price_dimensions.items():
                                price_per_unit = price_value.get('pricePerUnit', {}).get('USD', '0')
                                try:
                                    price_float = float(price_per_unit)
                                    if price_float > 0:
                                        region_ebs_prices['gp2'] = price_float
                                        return region_ebs_prices
                                except (ValueError, TypeError):
                                    continue
                            break
                    except (json.JSONDecodeError, KeyError):
                        continue
                        
        except Exception as e:
            logger.error(f"Error fetching EBS prices for region {region}: {e}")
            
        return region_ebs_prices

    def get_instance_details(self, region):
        """Fetches detailed instance information (vCPU, Mem) for a region."""
        if region in self._instance_details_cache:
            return self._instance_details_cache[region]
            
        ec2_client = self._get_ec2_client(region)
        if not ec2_client:
            return {}

        instance_types_details = {}
        try:
            paginator = ec2_client.get_paginator('describe_instance_types')
            response_iterator = paginator.paginate()
            
            for page in response_iterator:
                for instance_type_info in page['InstanceTypes']:
                    instance_type = instance_type_info['InstanceType']
                    if instance_type not in EXCLUDE_INSTANCE_TYPES:
                        vcpus = instance_type_info['VCpuInfo']['DefaultVCpus']
                        memory_mib = instance_type_info['MemoryInfo']['SizeInMiB']
                        memory_gib = memory_mib / 1024
                        instance_types_details[instance_type] = {
                            'vCPUs': vcpus,
                            'MemoryGiB': memory_gib
                        }
                        
        except Exception as e:
            logger.error(f"Error fetching instance details for {region}: {e}")
            
        self._instance_details_cache[region] = instance_types_details
        return instance_types_details

    def calculate_cost(self, instance_type, operating_system, region, storage_gb, ri_sp_option="On-Demand"):
        """Calculates the monthly cost for a given instance and storage."""
        instance_price = self.all_ec2_prices.get(region, {}).get(instance_type, {}).get(operating_system, 0.0)
        ebs_price_per_gb = self.all_ebs_prices.get(region, {}).get('gp2', 0.1)  # Default fallback

        if instance_price == 0.0:
            logger.warning(f"Instance price not found for {instance_type}/{operating_system} in {region}")
            return {'total_cost': float('inf'), 'instance_cost': float('inf'), 'ebs_cost': float('inf'), 'os_cost': 0}

        # Apply RI/SP discount
        discount_factor = 1.0 - RI_SP_DISCOUNTS.get(ri_sp_option, 0.0)
        
        # Calculate monthly costs (730 hours per month)
        monthly_instance_cost = instance_price * 730 * discount_factor
        monthly_ebs_cost = ebs_price_per_gb * storage_gb
        os_cost_component = 0  # Included in instance cost

        total_monthly_cost = monthly_instance_cost + monthly_ebs_cost

        return {
            'total_cost': total_monthly_cost,
            'instance_cost': monthly_instance_cost,
            'ebs_cost': monthly_ebs_cost,
            'os_cost': os_cost_component
        }

    def generate_all_recommendations(self):
        """Generates recommendations for DEV, UAT, and PROD environments."""
        recommendations = {}
        environments = ['DEV', 'UAT', 'PROD']
        
        for env in environments:
            try:
                vcpus = self.inputs.get(f'{env}_vcpus', 1)
                memory = self.inputs.get(f'{env}_memory_gb', 1.0)
                storage = self.inputs.get(f'{env}_storage_gb', 20)
                os = self.inputs.get(f'{env}_os', 'Linux')
                region = self.inputs.get(f'{env}_region', 'us-east-1')
                ri_sp_option = self.inputs.get('ri_sp_option', 'On-Demand')

                logger.info(f"Generating recommendations for {env}: vCPUs={vcpus}, Mem={memory}, Storage={storage}, OS={os}, Region={region}")

                instance_details_in_region = self.get_instance_details(region)
                region_ec2_prices = self.all_ec2_prices.get(region, {})

                best_instance = None
                min_cost = float('inf')
                cost_details = {}

                # Filter and sort instance types
                available_instance_types = [
                    it for it, os_prices in region_ec2_prices.items()
                    if os in os_prices and it in instance_details_in_region and it not in EXCLUDE_INSTANCE_TYPES
                ]

                available_instance_types.sort(key=lambda x: (
                    instance_details_in_region[x]['vCPUs'], 
                    instance_details_in_region[x]['MemoryGiB']
                ))

                for instance_type in available_instance_types:
                    details = instance_details_in_region.get(instance_type)
                    if not details:
                        continue

                    if details['vCPUs'] >= vcpus and details['MemoryGiB'] >= memory:
                        current_cost_details = self.calculate_cost(instance_type, os, region, storage, ri_sp_option)
                        current_total_cost = current_cost_details['total_cost']

                        if current_total_cost < min_cost:
                            min_cost = current_total_cost
                            best_instance = instance_type
                            cost_details = current_cost_details

                if best_instance:
                    recommendations[env] = {
                        'instance_type': best_instance,
                        'vcpus': instance_details_in_region[best_instance]['vCPUs'],
                        'memory_gb': instance_details_in_region[best_instance]['MemoryGiB'],
                        'storage_gb': storage,
                        'os': os,
                        'region': region,
                        'total_cost': min_cost,
                        'instance_cost': cost_details['instance_cost'],
                        'ebs_cost': cost_details['ebs_cost'],
                        'os_cost': cost_details['os_cost'],
                        'ri_sp_option': ri_sp_option
                    }
                else:
                    recommendations[env] = {
                        'instance_type': 'No suitable instance found',
                        'vcpus': 0, 'memory_gb': 0, 'storage_gb': storage,
                        'os': os, 'region': region, 'total_cost': float('inf'),
                        'instance_cost': float('inf'), 'ebs_cost': float('inf'), 'os_cost': 0,
                        'ri_sp_option': ri_sp_option
                    }
                    
            except Exception as e:
                logger.error(f"Error generating recommendations for {env}: {e}")
                recommendations[env] = {
                    'instance_type': f'Error: {str(e)}',
                    'vcpus': 0, 'memory_gb': 0, 'storage_gb': 0,
                    'os': '', 'region': '', 'total_cost': float('inf'),
                    'instance_cost': float('inf'), 'ebs_cost': float('inf'), 'os_cost': 0,
                    'ri_sp_option': ri_sp_option
                }

        # Calculate projected costs for PROD environment
        self._calculate_projected_costs(recommendations)
        
        return recommendations

    def _calculate_projected_costs(self, recommendations):
        """Calculate projected costs for PROD environment."""
        try:
            growth_rate = self.inputs.get('growth_rate_annual', 0.0) / 100
            growth_years = self.inputs.get('growth_years', 0)

            prod_recommendation = recommendations.get('PROD', {})
            if (prod_recommendation and 
                prod_recommendation['total_cost'] != float('inf') and 
                growth_rate > 0 and growth_years > 0):
                
                projected_costs = {}
                region = prod_recommendation['region']
                os = prod_recommendation['os']
                ri_sp_option = prod_recommendation['ri_sp_option']
                
                instance_details_in_region = self.get_instance_details(region)
                region_ec2_prices = self.all_ec2_prices.get(region, {})

                for year in range(1, growth_years + 1):
                    projected_vcpus = prod_recommendation['vcpus'] * (1 + growth_rate)**year
                    projected_memory = prod_recommendation['memory_gb'] * (1 + growth_rate)**year
                    projected_storage = prod_recommendation['storage_gb'] * (1 + growth_rate)**year
                    
                    # Find best instance for projected requirements
                    best_projected_instance = None
                    min_projected_cost = float('inf')

                    available_instance_types = [
                        it for it, os_prices in region_ec2_prices.items()
                        if os in os_prices and it in instance_details_in_region and it not in EXCLUDE_INSTANCE_TYPES
                    ]
                    
                    available_instance_types.sort(key=lambda x: (
                        instance_details_in_region[x]['vCPUs'], 
                        instance_details_in_region[x]['MemoryGiB']
                    ))

                    for instance_type in available_instance_types:
                        details = instance_details_in_region.get(instance_type)
                        if not details:
                            continue
                            
                        if details['vCPUs'] >= projected_vcpus and details['MemoryGiB'] >= projected_memory:
                            cost_details = self.calculate_cost(
                                instance_type, os, region, 
                                math.ceil(projected_storage), ri_sp_option
                            )
                            
                            if cost_details['total_cost'] < min_projected_cost:
                                min_projected_cost = cost_details['total_cost']
                                best_projected_instance = instance_type

                    projected_costs[f'Year {year}'] = {
                        'vcpus': math.ceil(projected_vcpus),
                        'memory_gb': math.ceil(projected_memory),
                        'storage_gb': math.ceil(projected_storage),
                        'estimated_cost': min_projected_cost if min_projected_cost != float('inf') else 'N/A',
                        'recommended_instance': best_projected_instance if best_projected_instance else 'N/A'
                    }
                    
                recommendations['PROD']['projected_costs'] = projected_costs
                
        except Exception as e:
            logger.error(f"Error calculating projected costs: {e}")


# --- Session State Management ---
def initialize_session_state():
    """Initializes all necessary session state variables."""
    if 'workload_inputs' not in st.session_state:
        st.session_state.workload_inputs = {
            'workload_name': '',
            'workload_type': WORKLOAD_TYPES[0],
            'PROD_vcpus': 2, 'PROD_memory_gb': 4, 'PROD_storage_gb': 100, 
            'PROD_os': OPERATING_SYSTEMS["Linux (Amazon Linux 2)"], 
            'PROD_region': AWS_REGIONS["US East (N. Virginia)"],
            'UAT_vcpus': 1, 'UAT_memory_gb': 2, 'UAT_storage_gb': 50, 
            'UAT_os': OPERATING_SYSTEMS["Linux (Amazon Linux 2)"], 
            'UAT_region': AWS_REGIONS["US East (N. Virginia)"],
            'DEV_vcpus': 1, 'DEV_memory_gb': 2, 'DEV_storage_gb': 50, 
            'DEV_os': OPERATING_SYSTEMS["Linux (Amazon Linux 2)"], 
            'DEV_region': AWS_REGIONS["US East (N. Virginia)"],
            'ri_sp_option': "On-Demand",
            'growth_rate_annual': 0,
            'growth_years': 5,
            
            # On-Premise Metrics
            'onprem_cpu_cores': 2,
            'onprem_current_storage_gb': 100,
            'onprem_cpu_model': "Intel Xeon E5",
            'onprem_storage_type': "SSD",
            'onprem_cpu_speed_ghz': 2.5,
            'onprem_raid_level': "RAID 1",
            'onprem_total_ram_gb': 8,
            'onprem_ram_type': "DDR4",
            'onprem_ram_speed_mhz': 2400,
            'onprem_annual_growth_rate_percent': 10,
            'onprem_planning_horizon_years': 5,
            'onprem_peak_cpu_utilization_percent': 70,
            'onprem_average_cpu_utilization_percent': 40,
            'onprem_active_cpu_cores': 2,
            'onprem_peak_ram_utilization_percent': 60,
            'onprem_average_ram_utilization_percent': 30,
            'onprem_sga_buffer_pool_gb': 0,
            'onprem_peak_iops': 1000,
            'onprem_average_iops': 500,
            'onprem_peak_throughput_mbps': 100,
            'onprem_network_bandwidth_gbps': 10,
            'onprem_network_latency_ms': 1,
            'onprem_max_concurrent_connections': 1000,
            'onprem_average_concurrent_connections': 500,

            # Advanced Settings
            'enable_encryption_at_rest': True,
            'enable_performance_insights': True,
            'enable_enhanced_monitoring': False,
            'monthly_data_transfer_gb': 500,
            'backup_retention_days': 7
        }
    if 'analysis_results' not in st.session_state:
        st.session_state.analysis_results = None
    if 'bulk_upload_df' not in st.session_state:
        st.session_state.bulk_upload_df = None
    if 'bulk_results' not in st.session_state:
        st.session_state.bulk_results = None
    if 'calculator' not in st.session_state:
        st.session_state.calculator = AWSCalculator()


# --- UI Rendering Functions ---
def render_workload_configuration():
    """Renders the UI for configuring a single workload."""
    st.markdown("## üìä Workload Requirements")

    st.session_state.workload_inputs['workload_name'] = st.text_input(
        "Workload Name (e.g., 'CRM Backend', 'Data Analytics')",
        value=st.session_state.workload_inputs['workload_name'],
        placeholder="Enter a descriptive name for your workload"
    )
    st.session_state.workload_inputs['workload_type'] = st.selectbox(
        "Workload Type",
        options=WORKLOAD_TYPES,
        index=WORKLOAD_TYPES.index(st.session_state.workload_inputs['workload_type'])
    )

    st.markdown("### Cost Optimization & Growth Projections")
    col_ri, col_growth_rate, col_growth_years = st.columns(3)
    with col_ri:
        st.session_state.workload_inputs['ri_sp_option'] = st.selectbox(
            "Pricing Model / Commitment",
            options=list(RI_SP_DISCOUNTS.keys()),
            help="Choose between On-Demand pricing or different Reserved Instance/Savings Plan commitments.",
            index=list(RI_SP_DISCOUNTS.keys()).index(st.session_state.workload_inputs['ri_sp_option'])
        )
    with col_growth_rate:
        st.session_state.workload_inputs['growth_rate_annual'] = st.number_input(
            "Annual Growth Rate (%)",
            min_value=0, max_value=50, 
            value=st.session_state.workload_inputs['growth_rate_annual'], 
            step=1,
            help="Estimate the percentage growth of your workload's resource requirements per year."
        )
    with col_growth_years:
        st.session_state.workload_inputs['growth_years'] = st.number_input(
            "Projection Years",
            min_value=0, max_value=10, 
            value=st.session_state.workload_inputs['growth_years'], 
            step=1,
            help="Number of years to project future costs based on the annual growth rate."
        )

    st.markdown("---")

    env_tabs = st.tabs([
        "Production (PROD)", 
        "User Acceptance Testing (UAT)", 
        "Development (DEV)", 
        "On-Premise Details", 
        "Advanced Settings"
    ])

    # Environment configuration tabs
    for i, env in enumerate(['PROD', 'UAT', 'DEV']):
        with env_tabs[i]:
            st.markdown(f"#### {env} Environment Requirements")
            col1, col2 = st.columns(2)
            with col1:
                st.session_state.workload_inputs[f'{env}_vcpus'] = st.number_input(
                    f"Required vCPUs ({env})",
                    min_value=1, max_value=128, 
                    value=st.session_state.workload_inputs[f'{env}_vcpus'], 
                    step=1, key=f'{env}_vcpus_input'
                )
                st.session_state.workload_inputs[f'{env}_storage_gb'] = st.number_input(
                    f"Required Storage (GB) ({env})",
                    min_value=1, max_value=16384, 
                    value=st.session_state.workload_inputs[f'{env}_storage_gb'], 
                    step=10, key=f'{env}_storage_gb_input',
                    help="Storage is estimated for EBS General Purpose SSD (gp2/gp3) volumes."
                )
            with col2:
                st.session_state.workload_inputs[f'{env}_memory_gb'] = st.number_input(
                    f"Required Memory (GiB) ({env})",
                    min_value=0.5, max_value=2048.0, 
                    value=float(st.session_state.workload_inputs[f'{env}_memory_gb']), 
                    step=0.5, key=f'{env}_memory_gb_input'
                )
                st.session_state.workload_inputs[f'{env}_os'] = st.selectbox(
                    f"Operating System ({env})",
                    options=list(OPERATING_SYSTEMS.values()),
                    index=list(OPERATING_SYSTEMS.values()).index(st.session_state.workload_inputs[f'{env}_os']), 
                    key=f'{env}_os_select'
                )
            
            # Region selection with error handling
            current_region_code = st.session_state.workload_inputs[f'{env}_region']
            default_region_key = "US East (N. Virginia)"
            
            try:
                current_region_name = next(k for k, v in AWS_REGIONS.items() if v == current_region_code)
            except StopIteration:
                logger.warning(f"Region code '{current_region_code}' not found for {env}. Defaulting to '{default_region_key}'.")
                current_region_name = default_region_key
                st.session_state.workload_inputs[f'{env}_region'] = AWS_REGIONS[default_region_key]

            selected_region_name = st.selectbox(
                f"Preferred AWS Region ({env})",
                options=list(AWS_REGIONS.keys()),
                index=list(AWS_REGIONS.keys()).index(current_region_name), 
                key=f'{env}_region_select'
            )
            st.session_state.workload_inputs[f'{env}_region'] = AWS_REGIONS[selected_region_name]
            st.markdown("---")
    
    # On-Premise Details Tab
    with env_tabs[3]:
        st.markdown("#### Existing On-Premise Workload Details")
        
        st.markdown("##### Compute")
        col1, col2, col3 = st.columns(3)
        with col1:
            st.session_state.workload_inputs['onprem_cpu_cores'] = st.number_input(
                "CPU Cores", min_value=1, max_value=256, 
                value=st.session_state.workload_inputs['onprem_cpu_cores'], 
                step=1, key="onprem_cpu_cores"
            )
            st.session_state.workload_inputs['onprem_cpu_model'] = st.text_input(
                "CPU Model", 
                value=st.session_state.workload_inputs['onprem_cpu_model'], 
                key="onprem_cpu_model"
            )
        with col2:
            st.session_state.workload_inputs['onprem_current_storage_gb'] = st.number_input(
                "Current Storage (GB)", min_value=1, max_value=65536, 
                value=st.session_state.workload_inputs['onprem_current_storage_gb'], 
                step=100, key="onprem_current_storage_gb"
            )
            st.session_state.workload_inputs['onprem_storage_type'] = st.selectbox(
                "Storage Type", 
                options=["HDD", "SSD", "NVMe", "SAN", "NAS"], 
                index=["HDD", "SSD", "NVMe", "SAN", "NAS"].index(st.session_state.workload_inputs['onprem_storage_type']), 
                key="onprem_storage_type"
            )
        with col3:
            st.session_state.workload_inputs['onprem_cpu_speed_ghz'] = st.number_input(
                "CPU Speed (GHz)", min_value=0.1, max_value=5.0, 
                value=st.session_state.workload_inputs['onprem_cpu_speed_ghz'], 
                step=0.1, format="%.1f", key="onprem_cpu_speed_ghz"
            )
            st.session_state.workload_inputs['onprem_raid_level'] = st.text_input(
                "RAID Level (If Applicable)", 
                value=st.session_state.workload_inputs['onprem_raid_level'], 
                key="onprem_raid_level"
            )

        # Continue with other on-premise sections...
        st.markdown("##### Memory Resources")
        col1, col2, col3 = st.columns(3)
        with col1:
            st.session_state.workload_inputs['onprem_total_ram_gb'] = st.number_input(
                "Total RAM (GB)", min_value=1, max_value=4096, 
                value=st.session_state.workload_inputs['onprem_total_ram_gb'], 
                step=4, key="onprem_total_ram_gb"
            )
        with col2:
            st.session_state.workload_inputs['onprem_ram_type'] = st.text_input(
                "RAM Type", 
                value=st.session_state.workload_inputs['onprem_ram_type'], 
                key="onprem_ram_type"
            )
        with col3:
            st.session_state.workload_inputs['onprem_ram_speed_mhz'] = st.number_input(
                "RAM Speed (MHz)", min_value=1000, max_value=5000, 
                value=st.session_state.workload_inputs['onprem_ram_speed_mhz'], 
                step=100, key="onprem_ram_speed_mhz"
            )

        # Additional on-premise sections would continue here...
        # (Including Growth & Planning, CPU Performance, RAM Utilization, I/O Performance, Network & Connection)
        # I'll include the key ones for brevity...

    # Advanced Settings Tab
    with env_tabs[4]:
        st.markdown("#### AWS Advanced Settings")
        st.session_state.workload_inputs['enable_encryption_at_rest'] = st.checkbox(
            "Enable Encryption at Rest (EBS)",
            value=st.session_state.workload_inputs['enable_encryption_at_rest'],
            help="Enables encryption for EBS volumes."
        )
        st.session_state.workload_inputs['enable_performance_insights'] = st.checkbox(
            "Enable Performance Insights (RDS/EC2)",
            value=st.session_state.workload_inputs['enable_performance_insights'],
            help="Enables database performance monitoring with Performance Insights."
        )
        # Additional advanced settings would continue here...

    # Configuration save/load section
    col_save, col_load = st.columns(2)
    with col_save:
        if st.button("üíæ Save Configuration", key="save_config"):
            try:
                inputs_to_save = st.session_state.workload_inputs.copy()
                file_name = f"{inputs_to_save.get('workload_name', 'workload_config').replace(' ', '_').lower()}.json"
                st.download_button(
                    label="Download Configuration JSON",
                    data=json.dumps(inputs_to_save, indent=4),
                    file_name=file_name,
                    mime="application/json",
                    key="download_config_btn"
                )
                st.success("Configuration ready for download!")
            except Exception as e:
                st.error(f"Error saving configuration: {e}")
    
    with col_load:
        uploaded_file = st.file_uploader("üìÇ Load Configuration", type="json", key="load_config_uploader")
        if uploaded_file is not None:
            try:
                loaded_inputs = json.load(uploaded_file)
                for key, default_value in st.session_state.workload_inputs.items():
                    if key not in loaded_inputs:
                        loaded_inputs[key] = default_value
                
                st.session_state.workload_inputs = {
                    k: loaded_inputs.get(k, v) for k, v in st.session_state.workload_inputs.items()
                }
                st.session_state.analysis_results = None
                st.success("Configuration loaded successfully! Click 'Generate Recommendations' to apply.")
                st.rerun()
            except json.JSONDecodeError:
                st.error("Invalid JSON file. Please upload a valid configuration file.")
            except Exception as e:
                st.error(f"Error loading configuration: {e}")


def render_analysis_results(recommendations, key_suffix=""):
    """Renders the analysis results for a single workload."""
    st.markdown("## ‚ú® Analysis Results")

    if not recommendations or 'error' in recommendations:
        st.warning(f"No recommendations available or an error occurred: {recommendations.get('error', 'Unknown Error')}")
        return

    # Prepare data for display
    data = []
    for env, rec in recommendations.items():
        if env == 'projected_costs':  # Skip projected costs in main table
            continue
            
        if rec.get('total_cost') == float('inf'):
            cost_str = "N/A (No suitable instance)"
            instance_str = "No suitable instance found"
            instance_cost = "N/A"
            ebs_cost = "N/A"
            os_cost = "N/A"
        else:
            cost_str = f"${rec.get('total_cost', 0):,.2f}/month"
            instance_str = f"{rec.get('instance_type', 'N/A')} ({rec.get('vcpus', 0)} vCPUs, {rec.get('memory_gb', 0):.1f} GiB)"
            instance_cost = f"${rec.get('instance_cost', 0):,.2f}"
            ebs_cost = f"${rec.get('ebs_cost', 0):,.2f}"
            os_cost = f"${rec.get('os_cost', 0):,.2f}"

        # Find region name safely
        region_name = "Unknown"
        region_code = rec.get('region', '')
        for name, code in AWS_REGIONS.items():
            if code == region_code:
                region_name = name
                break

        data.append({
            "Environment": env,
            "Recommended Instance": instance_str,
            "OS": rec.get('os', 'N/A'),
            "Region": region_name,
            "Storage (GB)": rec.get('storage_gb', 0),
            "EC2 Instance Cost": instance_cost,
            "EBS Storage Cost": ebs_cost,
            "OS Cost": os_cost,
            "Total Monthly Cost": cost_str
        })

    df_results = pd.DataFrame(data)
    st.dataframe(df_results, hide_index=True, use_container_width=True)

    # Cost Breakdown Chart for PROD
    st.markdown("### PROD Environment Cost Breakdown")
    prod_rec = recommendations.get('PROD')
    if prod_rec and prod_rec.get('total_cost', float('inf')) != float('inf'):
        cost_breakdown_data = {
            'Component': ['EC2 Instance', 'EBS Storage'],
            'Cost': [prod_rec.get('instance_cost', 0), prod_rec.get('ebs_cost', 0)]
        }
        df_costs = pd.DataFrame(cost_breakdown_data)
        df_costs = df_costs[df_costs['Cost'] > 0]  # Filter out zero costs
        
        if len(df_costs) > 0:
            fig_costs = px.pie(
                df_costs, values='Cost', names='Component', 
                title='PROD Monthly Cost Distribution', hole=0.4,
                color_discrete_sequence=px.colors.qualitative.Pastel
            )
            fig_costs.update_traces(
                textinfo='percent+label', 
                marker=dict(line=dict(color='#000000', width=1))
            )
            st.plotly_chart(fig_costs, use_container_width=True, key=f"prod_cost_chart_{key_suffix}")
    else:
        st.info("PROD environment recommendations not available for cost breakdown.")

    # Growth Projections
    st.markdown("### Workload Growth Projections (PROD)")
    if 'projected_costs' in recommendations.get('PROD', {}):
        proj_costs = recommendations['PROD']['projected_costs']
        proj_data = []
        for year_str, details in proj_costs.items():
            year_num = int(year_str.split(' ')[1])
            estimated_cost = details.get('estimated_cost', 'N/A')
            if isinstance(estimated_cost, (int, float)):
                proj_data.append({
                    "Year": year_num,
                    "Estimated Cost (Monthly)": estimated_cost,
                    "Projected vCPUs": details.get('vcpus', 0),
                    "Projected Memory (GiB)": details.get('memory_gb', 0),
                    "Projected Storage (GB)": details.get('storage_gb', 0),
                    "Recommended Instance": details.get('recommended_instance', 'N/A')
                })
        
        if proj_data:
            df_projected = pd.DataFrame(proj_data)
            
            # Plot projected costs
            fig_proj = px.line(
                df_projected, x="Year", y="Estimated Cost (Monthly)", 
                title="Projected Monthly Cost Over Time (PROD)", 
                markers=True
            )
            fig_proj.update_layout(
                hovermode="x unified", 
                xaxis_title="Year", 
                yaxis_title="Estimated Monthly Cost ($)"
            )
            st.plotly_chart(fig_proj, use_container_width=True, key=f"proj_cost_chart_{key_suffix}")
            
            st.dataframe(df_projected.set_index("Year"), use_container_width=True)
    else:
        st.info("No growth projection data available or growth rate not set.")


def render_bulk_analysis():
    """Renders the UI for bulk analysis."""
    st.markdown("## üì• Bulk Workload Analysis")

    # Define CSV template with corrected structure
    csv_columns = [
        "Workload Name", "Workload Type",
        "PROD_vCPUs", "PROD_Memory_GiB", "PROD_Storage_GB", "PROD_OS", "PROD_Region",
        "UAT_vCPUs", "UAT_Memory_GiB", "UAT_Storage_GB", "UAT_OS", "UAT_Region",
        "DEV_vCPUs", "DEV_Memory_GiB", "DEV_Storage_GB", "DEV_OS", "DEV_Region",
        "RI_SP_Option", "Annual Growth Rate (%)", "Projection Years"
    ]
    
    sample_data = [
        ["Sample Web App", "Web Application", 
         4, 8.0, 100, "Linux", "us-east-1",
         2, 4.0, 50, "Linux", "us-east-1",
         1, 2.0, 25, "Linux", "us-east-1",
         "On-Demand", 10, 5],
        ["Sample Database", "Database Server", 
         8, 32.0, 500, "RHEL", "us-west-2",
         4, 16.0, 250, "RHEL", "us-west-2",
         2, 8.0, 100, "RHEL", "us-west-2",
         "1-Year No Upfront RI/SP", 5, 3]
    ]
    
    df_template = pd.DataFrame(sample_data, columns=csv_columns)

    st.download_button(
        label="Download Bulk Upload Template (CSV)",
        data=df_template.to_csv(index=False).encode('utf-8'),
        file_name="bulk_workload_template.csv",
        mime="text/csv",
        help="Download a CSV template to fill in multiple workload requirements."
    )

    uploaded_file = st.file_uploader("Upload Workloads CSV", type="csv", key="bulk_csv_uploader")

    if uploaded_file is not None:
        try:
            df_uploaded = pd.read_csv(uploaded_file)
            st.session_state.bulk_upload_df = df_uploaded
            st.success(f"Successfully uploaded {len(df_uploaded)} workloads.")
            st.dataframe(df_uploaded, use_container_width=True, hide_index=True)
            
            if st.button("üöÄ Analyze All Workloads", key="analyze_bulk_btn"):
                analyze_bulk_workloads(df_uploaded)
                
        except Exception as e:
            st.error(f"Error reading CSV file: {e}")


def analyze_bulk_workloads(df_workloads):
    """Processes multiple workloads from a DataFrame and generates recommendations."""
    st.session_state.bulk_results = []
    total_workloads = len(df_workloads)
    analysis_progress_text = st.empty()
    analysis_progress_bar = st.progress(0)

    for i, row in df_workloads.iterrows():
        workload_name = row.get("Workload Name", f"Workload {i+1}")
        analysis_progress_text.text(f"Analyzing workload: {workload_name} ({i+1}/{total_workloads})...")
        analysis_progress_bar.progress((i + 1) / total_workloads)

        # Map CSV columns to calculator inputs with safe defaults
        current_workload_inputs = {
            'workload_name': workload_name,
            'workload_type': row.get("Workload Type", WORKLOAD_TYPES[0]),
            'PROD_vcpus': int(row.get("PROD_vCPUs", 1)),
            'PROD_memory_gb': float(row.get("PROD_Memory_GiB", 1.0)),
            'PROD_storage_gb': int(row.get("PROD_Storage_GB", 20)),
            'PROD_os': row.get("PROD_OS", "Linux"),
            'PROD_region': _get_region_code(row.get("PROD_Region", "us-east-1")),
            'UAT_vcpus': int(row.get("UAT_vCPUs", 1)),
            'UAT_memory_gb': float(row.get("UAT_Memory_GiB", 1.0)),
            'UAT_storage_gb': int(row.get("UAT_Storage_GB", 20)),
            'UAT_os': row.get("UAT_OS", "Linux"),
            'UAT_region': _get_region_code(row.get("UAT_Region", "us-east-1")),
            'DEV_vcpus': int(row.get("DEV_vCPUs", 1)),
            'DEV_memory_gb': float(row.get("DEV_Memory_GiB", 1.0)),
            'DEV_storage_gb': int(row.get("DEV_Storage_GB", 20)),
            'DEV_os': row.get("DEV_OS", "Linux"),
            'DEV_region': _get_region_code(row.get("DEV_Region", "us-east-1")),
            'ri_sp_option': row.get("RI_SP_Option", "On-Demand"),
            'growth_rate_annual': int(row.get("Annual Growth Rate (%)", 0)),
            'growth_years': int(row.get("Projection Years", 5))
        }
        
        # Set calculator inputs
        st.session_state.calculator.inputs = current_workload_inputs
        
        try:
            results = st.session_state.calculator.generate_all_recommendations()
            st.session_state.bulk_results.append({
                'workload_name': workload_name,
                'inputs': current_workload_inputs,
                'recommendations': results
            })
        except Exception as e:
            st.session_state.bulk_results.append({
                'workload_name': workload_name,
                'inputs': current_workload_inputs,
                'recommendations': {'error': f"Error processing workload: {e}"}
            })
            logger.error(f"Error processing bulk workload {workload_name}: {e}")

    analysis_progress_text.empty()
    analysis_progress_bar.empty()
    st.success("‚úÖ Bulk analysis completed successfully!")


def _get_region_code(region_input):
    """Helper function to convert region name or code to AWS region code."""
    if region_input in AWS_REGIONS.values():
        return region_input
    elif region_input in AWS_REGIONS:
        return AWS_REGIONS[region_input]
    else:
        logger.warning(f"Unknown region: {region_input}, defaulting to us-east-1")
        return "us-east-1"


def display_bulk_analysis_results(bulk_results):
    """Displays the results of bulk analysis."""
    st.markdown("### Bulk Analysis Summary")
    summary_data = []
    
    for item in bulk_results:
        workload_name = item['workload_name']
        recommendations = item.get('recommendations', {})
        
        if 'error' in recommendations:
            summary_data.append({
                "Workload Name": workload_name,
                "PROD Recommended Instance": "Error",
                "PROD Monthly Cost": "Error",
                "Status": "Failed"
            })
            continue
            
        prod_rec = recommendations.get('PROD', {})
        total_cost_prod = prod_rec.get('total_cost', float('inf'))
        
        if total_cost_prod == float('inf'):
            cost_str = "N/A (No suitable instance)"
            instance_str = "No suitable instance found"
            status = "Failed"
        else:
            cost_str = f"${total_cost_prod:,.2f}/month"
            instance_str = f"{prod_rec.get('instance_type', 'N/A')} ({prod_rec.get('vcpus', 0)} vCPUs, {prod_rec.get('memory_gb', 0):.1f} GiB)"
            status = "Success"

        summary_data.append({
            "Workload Name": workload_name,
            "PROD Recommended Instance": instance_str,
            "PROD Monthly Cost": cost_str,
            "Status": status
        })
    
    df_summary = pd.DataFrame(summary_data)
    st.dataframe(df_summary, use_container_width=True, hide_index=True)

    st.markdown("### Detailed Bulk Results")
    for i, item in enumerate(bulk_results):
        workload_name = item['workload_name']
        with st.expander(f"View Details for: {workload_name}"):
            # Temporarily set session_state.workload_inputs for render_analysis_results
            original_workload_inputs = st.session_state.workload_inputs.copy()
            st.session_state.workload_inputs = item['inputs']
            render_analysis_results(item['recommendations'], key_suffix=f"bulk_{i}")
            # Restore original inputs
            st.session_state.workload_inputs = original_workload_inputs


def generate_pdf_report(workload_name, inputs, recommendations):
    """Generates a PDF report for the given workload."""
    if not REPORTLAB_AVAILABLE:
        st.error("`reportlab` library not found. Please install it to generate PDF reports.")
        return None

    try:
        buffer = BytesIO()
        doc = SimpleDocTemplate(buffer, pagesize=letter)
        styles = getSampleStyleSheet()
        
        # Custom styles
        styles.add(ParagraphStyle(
            name='TitleStyle', fontSize=20, leading=24, alignment=TA_CENTER,
            spaceAfter=20, fontName='Helvetica-Bold'
        ))
        styles.add(ParagraphStyle(
            name='Heading1', fontSize=16, leading=18, spaceAfter=12,
            fontName='Helvetica-Bold', textColor=colors.HexColor('#4c51bf')
        ))

        story = []

        # Title
        story.append(Paragraph("Enterprise AWS EC2 Workload Sizing Report", styles['TitleStyle']))
        story.append(Paragraph(f"Workload Name: <b>{workload_name}</b>", styles['Heading1']))
        story.append(Paragraph(f"Report Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", styles['Normal']))
        story.append(Spacer(1, 0.2 * inch))

        # Workload Configuration
        story.append(Paragraph("1. Workload Configuration", styles['Heading1']))
        story.append(Paragraph(f"Workload Type: {inputs.get('workload_type', 'N/A')}", styles['Normal']))
        story.append(Paragraph(f"Pricing Model: {inputs.get('ri_sp_option', 'N/A')}", styles['Normal']))
        story.append(Spacer(1, 0.2 * inch))

        # Recommendations table
        story.append(Paragraph("2. AWS Recommendations", styles['Heading1']))
        
        table_data = [['Environment', 'Instance Type', 'vCPUs', 'Memory (GiB)', 'Storage (GB)', 'Monthly Cost']]
        
        for env in ['PROD', 'UAT', 'DEV']:
            rec = recommendations.get(env, {})
            if rec.get('total_cost', float('inf')) == float('inf'):
                cost_str = "N/A"
                instance_str = "No suitable instance"
            else:
                cost_str = f"${rec.get('total_cost', 0):,.2f}"
                instance_str = rec.get('instance_type', 'N/A')
            
            table_data.append([
                env,
                instance_str,
                str(rec.get('vcpus', 0)),
                f"{rec.get('memory_gb', 0):.1f}",
                str(rec.get('storage_gb', 0)),
                cost_str
            ])

        table = Table(table_data)
        table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, 0), 10),
            ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
            ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
            ('GRID', (0, 0), (-1, -1), 1, colors.black)
        ]))
        
        story.append(table)
        story.append(Spacer(1, 0.2 * inch))

        # Footer
        story.append(Paragraph("--- End of Report ---", styles['Normal']))

        doc.build(story)
        buffer.seek(0)
        return buffer
        
    except Exception as e:
        logger.error(f"Error generating PDF: {e}")
        st.error(f"Error generating PDF: {e}")
        return None


def render_reports_export():
    """Renders options to export reports."""
    st.markdown("## üìÑ Reports & Export")

    # Single Workload Report
    st.markdown("### Single Workload Report")
    if st.session_state.analysis_results:
        workload_name = st.session_state.analysis_results.get('inputs', {}).get('workload_name', 'Single_Workload_Analysis')
        
        if st.button("Generate PDF Report (Current Workload)", key="generate_pdf_single"):
            with st.spinner("Generating PDF..."):
                pdf_buffer = generate_pdf_report(
                    workload_name=workload_name,
                    inputs=st.session_state.analysis_results['inputs'],
                    recommendations=st.session_state.analysis_results['recommendations']
                )
                if pdf_buffer:
                    st.download_button(
                        label="Download PDF Report",
                        data=pdf_buffer.getvalue(),
                        file_name=f"{workload_name}_AWS_Sizing_Report.pdf",
                        mime="application/pdf"
                    )
                    st.success("PDF report generated!")
    else:
        st.info("Please generate recommendations for a single workload first.")

    # Bulk Workload Reports
    st.markdown("### Bulk Workload Reports")
    if st.session_state.bulk_results:
        if st.button("Export Bulk Results to CSV", key="export_bulk_csv"):
            bulk_export_data = []
            for item in st.session_state.bulk_results:
                recommendations = item.get('recommendations', {})
                prod_rec = recommendations.get('PROD', {})
                
                row_data = {
                    "Workload Name": item['workload_name'],
                    "Workload Type": item['inputs'].get('workload_type', ''),
                    "PROD_vCPUs_Req": item['inputs'].get('PROD_vcpus', 0),
                    "PROD_Memory_GiB_Req": item['inputs'].get('PROD_memory_gb', 0.0),
                    "PROD_Storage_GB_Req": item['inputs'].get('PROD_storage_gb', 0),
                    "PROD_Recommended_Instance": prod_rec.get('instance_type', 'N/A'),
                    "PROD_vCPUs_Rec": prod_rec.get('vcpus', 0),
                    "PROD_Memory_GiB_Rec": prod_rec.get('memory_gb', 0.0),
                    "PROD_Monthly_Cost_USD": prod_rec.get('total_cost', 0) if prod_rec.get('total_cost') != float('inf') else 'N/A'
                }
                bulk_export_data.append(row_data)

            df_bulk_export = pd.DataFrame(bulk_export_data)
            csv_export = df_bulk_export.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="Download All Bulk Results as CSV",
                data=csv_export,
                file_name=f"bulk_aws_sizing_results_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                mime="text/csv"
            )
            st.success("Bulk results CSV ready for download!")
    else:
        st.info("No bulk analysis results available to export.")


# Main Application Logic
def main():
    initialize_session_state()

    st.markdown("""
    <div class="main-header">
        <h1>Enterprise AWS EC2 Workload Sizing Platform</h1>
        <p>Comprehensive cloud migration planning for enterprise infrastructure</p>
    </div>
    """, unsafe_allow_html=True)

    with st.sidebar:
        st.markdown("### üîß Global Configuration")
        if st.button("‚öôÔ∏è Re-fetch Latest AWS Prices", key="fetch_prices_btn"):
            with st.spinner("Fetching latest prices..."):
                try:
                    st.session_state.calculator.fetch_current_prices()
                    if st.session_state.calculator.all_ec2_prices and st.session_state.calculator.all_ebs_prices:
                        st.success("‚úÖ Latest AWS prices fetched!")
                    else:
                        st.error("‚ùå Failed to fetch AWS prices.")
                except Exception as e:
                    st.error(f"‚ùå Error fetching prices: {e}")

        # Check AWS credentials status
        try:
            status, message = st.session_state.calculator.validate_aws_credentials()
            if status:
                st.success(f"AWS Connection: {message}")
            else:
                st.error(f"AWS Connection: {message}")
                st.info("Please ensure AWS credentials are set up properly.")
        except Exception as e:
            st.error(f"Error checking AWS credentials: {e}")
            status = False

    tab1, tab2, tab3 = st.tabs(["Single Workload Analysis", "Bulk Analysis", "Reports & Export"])

    with tab1:
        render_workload_configuration()
        if st.button("‚ú® Generate Recommendations", type="primary", key="generate_single_recommendation"):
            if not status:
                st.error("Cannot generate recommendations. AWS credentials are not properly configured.")
            else:
                if not st.session_state.calculator.all_ec2_prices:
                    st.info("Fetching AWS prices for the first time...")
                    st.session_state.calculator.fetch_current_prices()
                
                if not st.session_state.calculator.all_ec2_prices:
                    st.error("Failed to fetch AWS prices. Cannot proceed with recommendations.")
                else:
                    with st.spinner("Analyzing workload and generating recommendations..."):
                        try:
                            st.session_state.calculator.inputs = st.session_state.workload_inputs.copy()
                            results = st.session_state.calculator.generate_all_recommendations()
                            st.session_state.analysis_results = {
                                'inputs': st.session_state.workload_inputs.copy(),
                                'recommendations': results
                            }
                            st.success("‚úÖ Analysis completed successfully!")
                        except Exception as e:
                            st.error(f"‚ùå Error during analysis: {str(e)}")
                            logger.error(f"Analysis error: {e}")

        if st.session_state.analysis_results:
            st.markdown("---")
            render_analysis_results(
                st.session_state.analysis_results['recommendations'], 
                key_suffix="single_workload"
            )

    with tab2:
        render_bulk_analysis()
        if st.session_state.bulk_results:
            st.markdown("---")
            display_bulk_analysis_results(st.session_state.bulk_results)

    with tab3:
        render_reports_export()

    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; color: #6b7280; font-size: 0.875rem; padding: 2rem 0;">
        <strong>Enterprise AWS Workload Sizing Platform v3.0</strong><br>
        Comprehensive cloud migration planning for enterprise infrastructure
    </div>
    """, unsafe_allow_html=True)


if __name__ == "__main__":
    main()